Эксперимент был выполнен скриптом svm_base На PS_2007
В первом случае не использовалось масштабирование, а во втором случае использовался StandartScaler
Параметры SVM в обоих случаях были
params = {'kernel':'rbf',"C": 8,"gamma":0.125} 
и получены они были при отмасштабированных данных.
Видно, что в случае с использованием масштабирования на обучающей выбокре  0.98, а на тесте 0.95
а если оно не использовалось, то на обучении результат значитльно лучше - практически 1, а вот на тесте 0.91. 
Видно, что при масштабировании  оценка качества сбалансирована. 
Все таки масштабировать нужно, однако возникает вопрос - что делать с выбросами. 
Их наличиче сильно влияет на качество. 



##############################
			2007

C : 8.000000, gamma : 0.125000			 TRAIN 
                            precision    recall  f1-score   support

['а-76', 'ао укртатнафта']       1.00      1.00      1.00       178
         ['а-80', 'линик']       1.00      1.00      1.00        43
['а-92', 'ао укртатнафта']       1.00      0.99      1.00       154
         ['а-92', 'линик']       1.00      0.99      1.00       134
       ['а-92', 'мажейкю']       0.98      1.00      0.99        91
['а-95', 'ао укртатнафта']       1.00      1.00      1.00       132
         ['а-95', 'линик']       0.99      1.00      1.00       172
       ['а-95', 'мажейкю']       1.00      0.99      1.00       127
       ['а-95', 'румыния']       1.00      1.00      1.00        34
       ['а-98', 'мажейкю']       1.00      1.00      1.00        17

               avg / total       1.00      1.00      1.00      1082

			 TEST 
                            precision    recall  f1-score   support

['а-76', 'ао укртатнафта']       0.97      0.96      0.97        76
         ['а-80', 'линик']       0.93      0.78      0.85        18
['а-92', 'ао укртатнафта']       0.98      0.91      0.94        66
         ['а-92', 'линик']       0.95      0.90      0.92        58
       ['а-92', 'мажейкю']       0.97      0.82      0.89        39
['а-95', 'ао укртатнафта']       0.86      0.91      0.89        56
         ['а-95', 'линик']       0.76      0.95      0.84        74
       ['а-95', 'мажейкю']       0.94      0.93      0.94        55
       ['а-95', 'румыния']       0.93      0.87      0.90        15
       ['а-98', 'мажейкю']       1.00      0.86      0.92         7

               avg / total       0.92      0.91      0.91       464

-----------------------------------------
C масштабированием
##############################
			2007

C : 8.000000, gamma : 0.125000			 TRAIN 
                            precision    recall  f1-score   support

['а-76', 'ао укртатнафта']       0.99      0.99      0.99       178
         ['а-80', 'линик']       0.98      0.98      0.98        43
['а-92', 'ао укртатнафта']       0.99      0.98      0.98       154
         ['а-92', 'линик']       0.98      0.99      0.98       134
       ['а-92', 'мажейкю']       0.98      0.98      0.98        91
['а-95', 'ао укртатнафта']       0.99      0.95      0.97       132
         ['а-95', 'линик']       0.97      0.99      0.98       172
       ['а-95', 'мажейкю']       0.97      0.98      0.97       127
       ['а-95', 'румыния']       0.97      1.00      0.99        34
       ['а-98', 'мажейкю']       1.00      1.00      1.00        17

               avg / total       0.98      0.98      0.98      1082

			 TEST 
                            precision    recall  f1-score   support

['а-76', 'ао укртатнафта']       0.97      0.96      0.97        76
         ['а-80', 'линик']       0.94      0.89      0.91        18
['а-92', 'ао укртатнафта']       0.97      0.94      0.95        66
         ['а-92', 'линик']       0.95      0.95      0.95        58
       ['а-92', 'мажейкю']       0.95      0.95      0.95        39
['а-95', 'ао укртатнафта']       0.91      0.95      0.93        56
         ['а-95', 'линик']       0.95      0.96      0.95        74
       ['а-95', 'мажейкю']       0.96      0.95      0.95        55
       ['а-95', 'румыния']       0.88      1.00      0.94        15
       ['а-98', 'мажейкю']       1.00      1.00      1.00         7

               avg / total       0.95      0.95      0.95       464
